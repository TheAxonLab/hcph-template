{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import importlib\n",
    "\n",
    "import interpolation as interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to generate the high-definition grid (defined from the *MNI template* resampled here at `resolution = 0.6` mm), load the images to interpolate (located in `path_to_dir`) as well as the corresponding transforms (located in the `transform_dir` subfolder of `path_to_dir`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(interp)\n",
    "\n",
    "#path_to_der = \"/home/acionca/Documents/data/hcph-template/multivar-v00/derivatives/\"\n",
    "#der_name = \"histomatch\"\n",
    "\n",
    "path_to_data=\"/Users/acionca/data\"\n",
    "path_to_der = op.join(path_to_data, \"hcph-template/multivar-v00/derivatives/\")\n",
    "der_name = \"allInRef\"\n",
    "\n",
    "path_to_dir = op.join(path_to_der, der_name)\n",
    "\n",
    "resolution = 0.5\n",
    "#mni_grid = interp.generate_MNI_grid(resolution)\n",
    "\n",
    "path_to_initial_template = op.join(path_to_der, der_name, \"A_tpl_template0.nii.gz\")\n",
    "mni_grid = interp.generate_grid_from_img(path_to_initial_template, resolution)\n",
    "print(f\"Reference grid at resolution {resolution}mm has shape: {mni_grid.shape}\")\n",
    "\n",
    "transform_dir = \"ANTs_iteration_2\"\n",
    "path_to_transforms = op.join(path_to_dir, transform_dir)\n",
    "\n",
    "transforms_files = [op.join(path_to_transforms, file) for file in os.listdir(path_to_transforms) if \"Affine\" in file and \"template\" not in file]\n",
    "\n",
    "exclude = [\"ses-017\", \"ses-pilot019\"]\n",
    "for excl in exclude:\n",
    "    transforms_files = [file for file in transforms_files if excl not in file]\n",
    "\n",
    "transforms_files = sorted(transforms_files)\n",
    "\n",
    "anat_files = interp.get_anat_filenames(path_to_dir, pattern=\".nii.gz\")\n",
    "for excl in exclude:\n",
    "    anat_files = [file for file in anat_files if excl not in file]\n",
    "affine_transforms = interp.get_transforms(transforms_files, [mni_grid]*len(transforms_files))\n",
    "\n",
    "anat_files = anat_files[:5]\n",
    "affine_transforms = affine_transforms[:5]\n",
    "\n",
    "print(f\"{len(affine_transforms)} transforms found\")\n",
    "print(f\"{len(anat_files)} anat_files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the resampled images as well as the distance maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(interp)\n",
    "\n",
    "# To reduce memmory load and to parallelize the computation, the voxel indices\n",
    "# of the high-resolution grid are separated into `n_batches` batches.\n",
    "n_batches = 1000\n",
    "# This decides if we want to `weight` the interpolation using the projected distances.\n",
    "weight = True\n",
    "# This kernel is applied to the distances to give more weight to smaller values (see example)\n",
    "dist_kernel_order = 1\n",
    "# This is the order of the BSpline interpolation of the target images (usually 3 for cubic BSpline)\n",
    "spline_order = 3\n",
    "# The number of jobs to use for parallel execution (using *Joblib*)\n",
    "n_jobs = 25\n",
    "\n",
    "d_map, r_map = interp.get_individual_map(\n",
    "    mni_grid,\n",
    "    anat_files,\n",
    "    affine_transforms,\n",
    "    n_batches=n_batches,\n",
    "    spline_order=spline_order,\n",
    "    n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_map_backup = d_map.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look a the distance maps as well as the influence of normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(interp)\n",
    "\n",
    "MAX_DIST = np.sqrt(3 * (0.5 ** 2))\n",
    "\n",
    "slice_id = 100\n",
    "n_maps_to_show = 4\n",
    "\n",
    "distance_map_red = d_map[:n_maps_to_show]\n",
    "fig, axes = plt.subplots(nrows=len(distance_map_red), ncols=3, figsize=(15, 5*len(distance_map_red)))\n",
    "\n",
    "for ax, dist in zip(axes[:, 0], distance_map_red):\n",
    "    ax.set_title(\"Distance map\")\n",
    "    ax.imshow(dist[..., slice_id])\n",
    "\n",
    "for i, kernel_order in enumerate([1, 2, 5, 10]):\n",
    "    norm_distances = interp.normalize_distances(distance_map_red, dist_kernel_order=kernel_order, offset=0.1)\n",
    "    for ax, dist in zip(axes[:, i+1], norm_distances):\n",
    "        ax.set_title(f\"Normalized distance map\\n(order = {kernel_order})\")\n",
    "        ax.imshow(dist[..., slice_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show the influence of the BSpline kernel order to the distance weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10), sharex=True)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "\n",
    "k_order = [1, 2, 3]\n",
    "subsample = np.random.choice(np.arange(len(d_map.flatten())), 100)\n",
    "for i, offset in enumerate([0, 0.1]):\n",
    "    for k in k_order:\n",
    "        dmap = interp.normalize_distances(d_map, k, offset=offset)\n",
    "        axes[0, i].scatter(d_map.flatten()[subsample], dmap.flatten()[subsample], alpha=0.3, label=f\"Kernel order = {k}\")\n",
    "\n",
    "    axes[0, i].set_ylabel(\"Weight\")\n",
    "    axes[0, i].legend()\n",
    "\n",
    "    axes[1, i].hist(d_map.flatten(), bins=20, label=\"Distances\")\n",
    "    axes[1, i].set_xticks(np.arange(0, 1, 0.1))\n",
    "    axes[1, i].set_ylabel(\"Count\")\n",
    "    axes[1, i].set_xlabel(\"Distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can inspect the output of the interpolation procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_r_maps = r_map.__mul__(interp.normalize_distances(d_map, dist_kernel_order=dist_kernel_order))\n",
    "\n",
    "interpolated_map = weighted_r_maps.sum(axis=0)\n",
    "\n",
    "n_slices = 2\n",
    "slices = np.linspace(0, interpolated_map.shape[-1], n_slices+3, dtype=int)\n",
    "\n",
    "if resolution >= 1:\n",
    "    ZOOM1 = slice(50,100)\n",
    "    ZOOM2 = slice(100,150)\n",
    "elif resolution >= 0.8:\n",
    "    ZOOM1 = slice(120,180)\n",
    "    ZOOM2 = slice(120,180)\n",
    "elif resolution >= 0.4:\n",
    "    ZOOM1 = slice(150,250)\n",
    "    ZOOM2 = slice(100,200)\n",
    "else: # resolution < 0.4:\n",
    "    ZOOM1 = slice(200,300)\n",
    "    ZOOM2 = slice(200,300)\n",
    "\n",
    "vmax = 600\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_slices+1, figsize=(18, 18))\n",
    "\n",
    "for ax, i in zip(axes[:-1], slices[1:-2]):\n",
    "    ax.set_title(f\"Interpolated map: z = {i}\")\n",
    "    ax.imshow(interpolated_map[..., i], cmap=\"binary_r\", vmin=0, vmax=vmax)\n",
    "\n",
    "axes[-1].set_title(f\"Zoom: z = {i}\")\n",
    "axes[-1].imshow(interpolated_map[..., i][ZOOM1][:, ZOOM2], cmap=\"binary_r\", vmin=0, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally save the data as a compressed `.nii` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_interp = nib.Nifti1Image(interpolated_map.astype(np.int16), affine=mni_grid.affine)\n",
    "#dw_interp.header.set_data_dtype(\"float32\")\n",
    "dw_interp.header.set_data_dtype(\"int16\")\n",
    "\n",
    "suffix = f\"N{len(anat_files)}\"\n",
    "suffix += weight*f\"DisWei{dist_kernel_order}\"\n",
    "suffix += \"AllInRes_\"\n",
    "\n",
    "fname = f\"distance_weighted_template_res-{resolution}_desc-{suffix}T1w.nii.gz\"\n",
    "print(fname)\n",
    "saveloc = op.join(path_to_data, \"hcph-template/multivar-v00/derivatives/diswe_interpolation\")\n",
    "dw_interp.to_filename(op.join(saveloc, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "\n",
    "norm_dist = interp.normalize_distances(d_map[:-1], dist_kernel_order=2)\n",
    "weighted_img = r_map[:-1].__mul__(norm_dist)\n",
    "\n",
    "print(len(weighted_img))\n",
    "\n",
    "axes[0].imshow(weighted_img.sum(axis=0)[..., slice_id])\n",
    "axes[1].imshow(weighted_img.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(18, 18))\n",
    "slice_id = 100\n",
    "\n",
    "#norm_dist = interp.normalize_distances(d_map[-1], dist_kernel_order=2)\n",
    "#weighted_img = r_map[-1].__mul__(norm_dist)\n",
    "\n",
    "axes[0, 0].imshow(r_map[-1][..., slice_id][50:200][:, 50:250])\n",
    "axes[0, 1].imshow(r_map[-1][..., slice_id][ZOOM1][:, ZOOM2])\n",
    "axes[1, 0].imshow(d_map[-1][..., slice_id], vmin=0, vmax=1)\n",
    "axes[1, 1].imshow(d_map[-1][..., slice_id][ZOOM1][:, ZOOM2], vmin=0, vmax=1)\n",
    "#axes[2].set_title(f\"Using {len(weighted_img)} imgs\")\n",
    "#axes[2].imshow(weighted_img.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=d_map.shape[0], ncols=3, figsize=(18, 6*d_map.shape[0]))\n",
    "slice_id = 100\n",
    "\n",
    "for i, axes_row in enumerate(axes[:-1]):\n",
    "    if i > 30:\n",
    "        axes_row[0].imshow(r_map[:i+1].mean(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "        norm_dist = interp.normalize_distances(d_map[:i+1], dist_kernel_order=2)\n",
    "        axes_row[1].imshow(norm_dist[i][..., slice_id][ZOOM1][:, ZOOM2], vmin=0, vmax=1)\n",
    "        weighted_img = r_map[:i+1].__mul__(norm_dist)\n",
    "        axes_row[2].set_title(f\"Using {len(weighted_img)} imgs\")\n",
    "        axes_row[2].imshow(weighted_img.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "\n",
    "diff_img = weighted_img.sum(axis=0) - r_map.mean(axis=0)\n",
    "axes[-1, 0].imshow(weighted_img.sum(axis=0)[..., slice_id])\n",
    "axes[-1, 1].imshow(diff_img[..., slice_id], vmin=-10, vmax=10, cmap=\"coolwarm\")\n",
    "axes[-1, 2].imshow(diff_img[..., slice_id][ZOOM1][:, ZOOM2], vmin=-10, vmax=10, cmap=\"coolwarm\")\n",
    "\n",
    "del weighted_img\n",
    "\n",
    "#axes[-1, 0].imshow(r_map.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "#axes[-1, 1].imshow(norm_dist.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "#axes[-1, 2].imshow(np.array(weighted).sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_dist = interp.normalize_distances(d_map, dist_kernel_order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=d_map.shape[0]+1, ncols=3, figsize=(12, 5*d_map.shape[0]))\n",
    "slice_id = 100\n",
    "\n",
    "weighted = []\n",
    "for i, axes_row in enumerate(axes[:-1]):\n",
    "    axes_row[0].imshow(r_map[i][..., slice_id][ZOOM1][:, ZOOM2])\n",
    "    axes_row[1].imshow(d_map[i][..., slice_id][ZOOM1][:, ZOOM2], vmin=0, vmax=1)\n",
    "    weighted_img = r_map[i].__mul__(norm_dist[i])\n",
    "    weighted.append(weighted_img)\n",
    "    axes_row[2].imshow(weighted_img[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "\n",
    "axes[-1, 0].imshow(r_map.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "d_imshow = axes[-1, 1].imshow(norm_dist.sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "axes[-1, 2].imshow(np.array(weighted).sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "\n",
    "plt.colorbar(d_imshow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(17, 6))\n",
    "\n",
    "axes[0].imshow(r_map.mean(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "axes[1].imshow(np.array(weighted).sum(axis=0)[..., slice_id][ZOOM1][:, ZOOM2])\n",
    "diff_map = r_map.mean(axis=0) - np.array(weighted).sum(axis=0)\n",
    "cbar = axes[2].imshow(diff_map[..., slice_id][ZOOM1][:, ZOOM2], vmin=-10, vmax=10, cmap=\"coolwarm\")\n",
    "plt.colorbar(cbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcph-qct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
